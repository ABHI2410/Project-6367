{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOxzlrkws+sScFmjLrc9XrT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABHI2410/Project-6367/blob/main/machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup**"
      ],
      "metadata": {
        "id": "BkxiadcJFfny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm opencv-python einops mediapipe tensorflow==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6UpnJQwFnhY",
        "outputId": "027e2967-d54a-45a2-cbb6-c78d62b8d7ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m687.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mediapipe\n",
            "  Downloading mediapipe-0.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.8.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.32.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.40.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.3.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, einops, sounddevice, mediapipe, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed einops-0.6.1 keras-2.13.1 mediapipe-0.10.2 sounddevice-0.4.6 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9-pWcklH5aU3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import cv2\n",
        "import einops\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mediapipe as mp\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "VIDEO_COUNT = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqUvuuKATBa",
        "outputId": "53e574eb-1a88-4bf1-f5a5-10ec0ae037b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre Processing Data**"
      ],
      "metadata": {
        "id": "qmWvsZZXGMFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLableEncoder():\n",
        "    def __init__(self):\n",
        "        self.label_encoder = preprocessing.LabelEncoder()\n",
        "        self.df = pd.read_csv('/content/drive/MyDrive/ASL_Videos/how2sign_realigned_train.csv', sep= \"\t\", header= 0)\n",
        "\n",
        "\n",
        "    def transform(self, data_to_transform):\n",
        "        text = []\n",
        "        data = \"\"\n",
        "        for index, row in self.df.iterrows():\n",
        "            data = row['SENTENCE'][:-1].lower().split(' ')\n",
        "            text = text + [i  for i in data if i not in text]\n",
        "        self.label_encoder = preprocessing.LabelEncoder()\n",
        "        self.label_encoder.fit(text)\n",
        "        return self.label_encoder.transform(data_to_transform)"
      ],
      "metadata": {
        "id": "QC-ZSLtV8Vfl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KeyPointDetector():\n",
        "    def __init__(self,path, frame_number):\n",
        "        self.path = '/content/drive/MyDrive/ASL_Videos/'\n",
        "        self.holistic = mp.solutions.holistic\n",
        "        self.output_path = path.split('.')[0]\n",
        "        self.file_name = frame_number\n",
        "\n",
        "    def extract_keypoints(self,results):\n",
        "        pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
        "        face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
        "        lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
        "        rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
        "        final_data = np.concatenate([pose, face, lh, rh])\n",
        "        np.save(str(self.path)+'/processed_data/'+str(self.file_name), final_data)\n",
        "        return final_data\n",
        "\n",
        "\n",
        "    def keypoints(self,image):\n",
        "        mediapipe_holistic = self.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "        image.flags.writeable = False\n",
        "        outcome = mediapipe_holistic.process(image)\n",
        "        image.flags.writeable = True\n",
        "        mediapipe_holistic.close()\n",
        "        return self.extract_keypoints(outcome)\n",
        "\n"
      ],
      "metadata": {
        "id": "A_GUJx9pO6WP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FrameGenerator():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/ASL_Videos/how2sign_realigned_train.csv', sep= \"\t\", header= 0)\n",
        "    video_path = '/content/drive/MyDrive/ASL_Videos/raw_videos/'\n",
        "\n",
        "    def get_video_and_label(self):\n",
        "        encoder = CustomLableEncoder()\n",
        "        labels = list()\n",
        "        videos = list()\n",
        "        for index, row in self.df.iterrows():\n",
        "            data = row['SENTENCE'][:-1].lower().split(' ')\n",
        "            video = row['SENTENCE_NAME'] + \".mp4\"\n",
        "            labels.append(encoder.transform(data))\n",
        "            if os.path.exists(self.video_path + video):\n",
        "                videos.append(self.video_path + video)\n",
        "            else:\n",
        "                print(\"Video not found\", video)\n",
        "                exit()\n",
        "        return videos, labels\n",
        "\n",
        "\n",
        "    def __call__(self):\n",
        "        video_path, labels = self.get_video_and_label()\n",
        "        data_lable_pair = list(zip(video_path, labels))\n",
        "\n",
        "        random.shuffle(data_lable_pair)\n",
        "        for path,lable in data_lable_pair:\n",
        "            video_frames = []\n",
        "            cap = cv2.VideoCapture(path)\n",
        "            frame_number = 0\n",
        "            VIDEO_COUNT += 1\n",
        "            print(VIDEO_COUNT)\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                landmarks = KeyPointDetector()\n",
        "                video_frames.append(landmarks.keypoints(frame,path,frame_number))\n",
        "                frame_number += 1\n",
        "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "                    break\n",
        "            cap.release()\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "            yield video_frames, lable\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oqO3vV1EBS-L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "output_signature = (tf.TensorSpec(shape = (1662), dtype = tf.float32),\n",
        "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
        "train_ds = tf.data.Dataset.from_generator(FrameGenerator(), output_signature= output_signature)\n",
        "\n",
        "train_ds = train_ds.batch(batch_size)\n"
      ],
      "metadata": {
        "id": "5pQ05-PqTAk3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HEIGHT = 720\n",
        "WIDTH = 1280"
      ],
      "metadata": {
        "id": "gqA3u6GrgAZg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv3Dim(keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, padding):\n",
        "        super().__init__()\n",
        "        self.seq = keras.Sequential([\n",
        "            layers.Conv3D(filters = filters,\n",
        "                          kernel_size = (1,kernel_size[1],kernel_size[2]),\n",
        "                          padding=padding),\n",
        "            layers.Conv3D(filters = filters,\n",
        "                          kernel_size = (kernel_size[0],1,1),\n",
        "                          padding=padding),\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.seq(inputs)"
      ],
      "metadata": {
        "id": "jhS1mwg_gLNf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualMain(keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, filters, kernel_size):\n",
        "    super().__init__()\n",
        "    self.seq = keras.Sequential([\n",
        "        Conv3Dim(filters=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    padding='same'),\n",
        "        layers.LayerNormalization(),\n",
        "        layers.ReLU(),\n",
        "        Conv3Dim(filters=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    padding='same'),\n",
        "        layers.LayerNormalization()\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.seq(inputs)"
      ],
      "metadata": {
        "id": "4Zo8C0wWikbw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Project(keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    self.seq = keras.Sequential([\n",
        "        layers.Dense(units),\n",
        "        layers.LayerNormalization()\n",
        "    ])\n",
        "\n",
        "  def call(self, input):\n",
        "    return self.seq(input)"
      ],
      "metadata": {
        "id": "2cCPuas7i1qf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_residual_block(input, filters, kernel_size):\n",
        "  out = ResidualMain(filters,\n",
        "                     kernel_size)(input)\n",
        "\n",
        "  res = input\n",
        "  if out.shape[-1] != input.shape[-1]:\n",
        "    res = Project(out.shape[-1])(res)\n",
        "\n",
        "  return layers.add([res, out])"
      ],
      "metadata": {
        "id": "p-zH-Uw-i9g1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeVideo(keras.layers.Layer):\n",
        "  def __init__(self, height, width):\n",
        "    super().__init__()\n",
        "    self.height = height\n",
        "    self.width = width\n",
        "    self.resizing_layer = layers.Resizing(self.height, self.width)\n",
        "\n",
        "  def call(self, video):\n",
        "    # b stands for batch size, t stands for time, h stands for height,\n",
        "    # w stands for width, and c stands for the number of channels.\n",
        "    old_shape = einops.parse_shape(video, 'b t h w c')\n",
        "    images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
        "    images = self.resizing_layer(images)\n",
        "    videos = einops.rearrange(\n",
        "        images, '(b t) h w c -> b t h w c',\n",
        "        t = old_shape['t'])\n",
        "    return videos"
      ],
      "metadata": {
        "id": "_0dhH00ijPZk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (None, 10, HEIGHT, WIDTH, 3)\n",
        "input = layers.Input(shape=(input_shape[1:]))\n",
        "x = input\n",
        "\n",
        "x = Conv3Dim(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.ReLU()(x)\n",
        "x = ResizeVideo(HEIGHT // 2, WIDTH // 2)(x)\n",
        "\n",
        "# Block 1\n",
        "x = add_residual_block(x, 16, (3, 3, 3))\n",
        "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)\n",
        "\n",
        "# Block 2\n",
        "x = add_residual_block(x, 32, (3, 3, 3))\n",
        "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)\n",
        "\n",
        "# Block 3\n",
        "x = add_residual_block(x, 64, (3, 3, 3))\n",
        "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)\n",
        "\n",
        "# Block 4\n",
        "x = add_residual_block(x, 128, (3, 3, 3))\n",
        "\n",
        "x = layers.GlobalAveragePooling3D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(10)(x)\n",
        "\n",
        "model = keras.Model(input, x)"
      ],
      "metadata": {
        "id": "j6Cmhus0jaVM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames, label = next(iter(train_ds))\n",
        "model.build(frames)"
      ],
      "metadata": {
        "id": "VuiNKkmwjohX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, expand_nested=True, dpi=60, show_shapes=True)"
      ],
      "metadata": {
        "id": "5bDD1CO2jua_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer = keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Mlw1QvMmkIvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x = train_ds,\n",
        "                    epochs = 10,\n",
        "                    validation_data = val_ds)"
      ],
      "metadata": {
        "id": "qCxra55AkNxj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}